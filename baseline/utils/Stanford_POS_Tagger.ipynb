{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnig the stanford pos tagger in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "from nltk import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Just', 'a', 'small', 'snippet', 'of', 'text', '.']\n"
     ]
    }
   ],
   "source": [
    "text_tok = nltk.word_tokenize(\"Just a small snippet of text.\")\n",
    "\n",
    "print(text_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Just', 'RB'), ('a', 'DT'), ('small', 'JJ'), ('snippet', 'NN'), ('of', 'IN'), ('text', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged = nltk.pos_tag(text_tok)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just_RB\n",
      "a_DT\n",
      "small_JJ\n",
      "snippet_NN\n",
      "of_IN\n",
      "text_NN\n",
      "._.\n"
     ]
    }
   ],
   "source": [
    "for word, word_class in pos_tagged:\n",
    "    print(word + \"_\" + word_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {'CC': 'coordinating conjunction',\n",
    "        'CD': 'cardinal digit',\n",
    "        'DT': 'determiner',\n",
    "        'EX': 'existential there (like: \\\"there is\\\" ... think of it like \\\"there exists\\\")',\n",
    "        'FW': 'foreign word',\n",
    "        'IN':  'preposition/subordinating conjunction',\n",
    "        'JJ': 'adjective \\'big\\'',\n",
    "        'JJR': 'adjective, comparative \\'bigger\\'',\n",
    "        'JJS': 'adjective, superlative \\'biggest\\'',\n",
    "        'LS': 'list marker 1)',\n",
    "        'MD': 'modal could, will',\n",
    "        'NN': 'noun, singular \\'desk\\'',\n",
    "        'NNS': 'noun plural \\'desks\\'',\n",
    "        'NNP': 'proper noun, singular \\'Harrison\\'',\n",
    "        'NNPS': 'proper noun, plural \\'Americans\\'',\n",
    "        'PDT': 'predeterminer \\'all the kids\\'',\n",
    "        'POS': 'possessive ending parent\\'s',\n",
    "        'PRP': 'personal pronoun I, he, she',\n",
    "        'PRP$': 'possessive pronoun my, his, hers',\n",
    "        'RB': 'adverb very, silently,',\n",
    "        'RBR': 'adverb, comparative better',\n",
    "        'RBS': 'adverb, superlative best',\n",
    "        'RP': 'particle give up',\n",
    "        'TO': 'to go \\'to\\' the store.',\n",
    "        'UH': 'interjection errrrrrrrm',\n",
    "        'VB': 'verb, base form take',\n",
    "        'VBD': 'verb, past tense took',\n",
    "        'VBG': 'verb, gerund/present participle taking',\n",
    "        'VBN': 'verb, past participle taken',\n",
    "        'VBP': 'verb, sing. present, non-3d take',\n",
    "        'VBZ': 'verb, 3rd person sing. present takes',\n",
    "        'WDT': 'wh-determiner which',\n",
    "        'WP': 'wh-pronoun who, what',\n",
    "        'WP$': 'possessive wh-pronoun whose',\n",
    "        'WRB': 'wh-abverb where, when',\n",
    "        'QF' : 'quantifier, bahut, thoda, kam (Hindi)',\n",
    "        'VM' : 'main verb',\n",
    "        'PSP' : 'postposition, common in indian langs',\n",
    "        'DEM' : 'demonstrative, common in indian langs'\n",
    "}\n",
    "\n",
    "exp = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "imp = ['JJ', 'JJR', 'JJS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'VM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('phone', 'NN'), ('has', 'VBZ'), ('great', 'JJ'), ('display', 'NN'), ('perfect', 'JJ'), ('size', 'NN'), ('great', 'JJ'), ('features', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "example1 = 'This phone has great display and perfect size. Its very fast with all great features.'\n",
    "\n",
    "text_tok_exp1 = nltk.word_tokenize(example1)\n",
    "\n",
    "pos_tagged_exp1 = nltk.pos_tag(text_tok_exp1)\n",
    "\n",
    "list_features = []\n",
    "for word, word_class in pos_tagged_exp1:\n",
    "    if word_class in exp:\n",
    "        list_features.append((word, word_class))\n",
    "        \n",
    "    if word_class in imp:\n",
    "        list_features.append((word, word_class))\n",
    "        \n",
    "print(list_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXemplo 2\n",
    "\n",
    "jar = '../../stanford-postagger-full-2020-11-17/stanford-postagger.jar'\n",
    "model = '../../stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger' # esse mdoelo Ã© melhor que o default do NLTK\n",
    "\n",
    "st = StanfordPOSTagger(model, jar, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('software', 'NN')] []\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize('software')\n",
    "tagge_words = st.tag(words)\n",
    "\n",
    "list_features_exp = []\n",
    "list_features_imp = []\n",
    "\n",
    "for word, word_class in tagge_words:\n",
    "    if word_class in exp:\n",
    "        list_features_exp.append((word, word_class))\n",
    "        \n",
    "    if word_class in imp:\n",
    "        list_features_imp.append(word)\n",
    "        \n",
    "print(list_features_exp, list_features_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p='#'\n",
    "p+='#'\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('software', 'NN')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize('software')\n",
    "tagge_words = st.tag(words)\n",
    "tagge_words[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
